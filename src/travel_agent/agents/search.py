"""Search Agent - æƒ…æŠ¥å®˜ (Intel Officer)

è´Ÿè´£äº’è”ç½‘æœç´¢ï¼Œå¯¹ç»“æœè¿›è¡Œå»å™ªã€æ—¶æ•ˆæ€§åˆ¤æ–­å’Œæ¥æºå¼•ç”¨ã€‚
æ”¯æŒåŠ¨æ€ä¸Šä¸‹æ–‡æ›¿æ¢ï¼Œè§£å†³ Planner å ä½ç¬¦é—®é¢˜ã€‚
"""

import re
import json
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.language_models import BaseChatModel

from ..graph.state import GraphState
from ..debug import debug_print, print_node_enter, print_routing, print_trip_data_update, print_kv, print_section


# å¸¸è§å ä½ç¬¦æ¨¡å¼
PLACEHOLDER_PATTERNS = [
    r"\{[\w_]+\}",           # å¤§æ‹¬å·æ ¼å¼: {hotel_name}, {golf_course} ç­‰
    r"hotel\s*name",
    r"the\s+hotel",
    r"place\s*name",
    r"golf\s*course\s*name",
    r"the\s+course",
    r"restaurant\s*name",
    r"the\s+restaurant",
    r"location\s*name",
    r"entity\s*name",
]


def _has_placeholder(query: str) -> bool:
    """æ£€æµ‹æŸ¥è¯¢æ˜¯å¦åŒ…å«å ä½ç¬¦"""
    query_lower = query.lower()
    for pattern in PLACEHOLDER_PATTERNS:
        if re.search(pattern, query_lower, re.IGNORECASE):
            return True
    return False


def _extract_entities_from_context(state: GraphState) -> dict:
    """ä» trip_data ä¸­æå–å¯ç”¨çš„å®ä½“åç§°

    Returns:
        {
            "hotel": "é…’åº—åç§°",
            "golf_course": "çƒåœºåç§°",
            "location": "ç›®çš„åœ°",
            ...
        }
    """
    entities = {}
    trip_data = state.get("trip_data", {})

    # æå–é…’åº—åç§°
    hotel_bookings = trip_data.get("hotel_bookings", [])
    if hotel_bookings:
        for booking in hotel_bookings:
            hotel_name = booking.get("hotel_name") or booking.get("hotel_name_en")
            if hotel_name and hotel_name != "æœªçŸ¥é…’åº—":
                entities["hotel"] = hotel_name
                break

    # æå–çƒåœºåç§°
    golf_bookings = trip_data.get("golf_bookings", [])
    if golf_bookings:
        for booking in golf_bookings:
            course_name = booking.get("course_name") or booking.get("course_name_en")
            if course_name:
                entities["golf_course"] = course_name
                break

    # ä»è¡Œç¨‹ä¿¡æ¯æå–ç›®çš„åœ°
    trip_info = trip_data.get("trip_info", {})
    if trip_info:
        location = trip_info.get("location") or trip_info.get("destination")
        if location:
            entities["location"] = location

    # ä» events ä¸­æå–å®ä½“ï¼ˆå¦‚æœä¸Šé¢æ²¡æ‰¾åˆ°ï¼‰
    events = trip_data.get("events", [])
    for event in events:
        event_type = event.get("type", "").lower()
        event_name = event.get("name") or event.get("description", "")

        if "hotel" not in entities and "é…’åº—" in event_type:
            entities["hotel"] = event_name
        if "golf_course" not in entities and ("çƒåœº" in event_type or "golf" in event_type):
            entities["golf_course"] = event_name

    return entities


def _refine_query_with_context(query: str, state: GraphState, llm: BaseChatModel) -> str:
    """ä½¿ç”¨ä¸Šä¸‹æ–‡æ›¿æ¢æŸ¥è¯¢ä¸­çš„å ä½ç¬¦

    ç­–ç•¥ï¼š
    1. å…ˆå°è¯•è§„åˆ™æ›¿æ¢ï¼ˆä» trip_data æå–å®ä½“ï¼‰
    2. å¦‚æœè§„åˆ™æ›¿æ¢å¤±è´¥ï¼Œä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ›¿æ¢
    """
    # 1. æå–å¯ç”¨å®ä½“
    entities = _extract_entities_from_context(state)
    debug_print(f"[Search Agent] å¯ç”¨å®ä½“: {entities}")

    if not entities:
        debug_print("[Search Agent] æ— å¯ç”¨å®ä½“è¿›è¡Œæ›¿æ¢")
        return query

    # 2. è§„åˆ™æ›¿æ¢
    refined_query = query
    query_lower = query.lower()

    # é…’åº—åç§°æ›¿æ¢
    if "hotel" in entities:
        hotel_name = entities["hotel"]
        for pattern in [r"hotel\s*name", r"the\s+hotel"]:
            if re.search(pattern, query_lower, re.IGNORECASE):
                refined_query = re.sub(pattern, hotel_name, refined_query, flags=re.IGNORECASE)
                debug_print(f"[Search Agent] æ›¿æ¢é…’åº—åç§°: {hotel_name}")

    # çƒåœºåç§°æ›¿æ¢
    if "golf_course" in entities:
        course_name = entities["golf_course"]
        for pattern in [r"golf\s*course\s*name", r"the\s+course"]:
            if re.search(pattern, query_lower, re.IGNORECASE):
                refined_query = re.sub(pattern, course_name, refined_query, flags=re.IGNORECASE)
                debug_print(f"[Search Agent] æ›¿æ¢çƒåœºåç§°: {course_name}")

    # åœ°ç‚¹åç§°æ›¿æ¢
    if "location" in entities:
        location = entities["location"]
        for pattern in [r"place\s*name", r"location\s*name"]:
            if re.search(pattern, query_lower, re.IGNORECASE):
                refined_query = re.sub(pattern, location, refined_query, flags=re.IGNORECASE)
                debug_print(f"[Search Agent] æ›¿æ¢åœ°ç‚¹: {location}")

    # å¤§æ‹¬å·æ ¼å¼å ä½ç¬¦æ›¿æ¢ (å¦‚ {hotel_name}, {golf_course})
    if "hotel" in entities:
        hotel_name = entities["hotel"]
        if re.search(r"\{hotel_name\}", refined_query, re.IGNORECASE):
            refined_query = re.sub(r"\{hotel_name\}", hotel_name, refined_query, flags=re.IGNORECASE)
            debug_print(f"[Search Agent] æ›¿æ¢ {{hotel_name}}: {hotel_name}")

    if "golf_course" in entities:
        course_name = entities["golf_course"]
        for pattern in [r"\{golf_course\}", r"\{course_name\}"]:
            if re.search(pattern, refined_query, re.IGNORECASE):
                refined_query = re.sub(pattern, course_name, refined_query, flags=re.IGNORECASE)
                debug_print(f"[Search Agent] æ›¿æ¢çƒåœºå ä½ç¬¦: {course_name}")

    if "location" in entities:
        location = entities["location"]
        for pattern in [r"\{location\}", r"\{place_name\}"]:
            if re.search(pattern, refined_query, re.IGNORECASE):
                refined_query = re.sub(pattern, location, refined_query, flags=re.IGNORECASE)
                debug_print(f"[Search Agent] æ›¿æ¢åœ°ç‚¹å ä½ç¬¦: {location}")

    # 3. å¦‚æœè§„åˆ™æ›¿æ¢åä»æœ‰å ä½ç¬¦ï¼Œå°è¯• LLM æ›¿æ¢
    if _has_placeholder(refined_query) and llm:
        debug_print("[Search Agent] è§„åˆ™æ›¿æ¢ä¸å®Œå…¨ï¼Œå°è¯• LLM ä¼˜åŒ–")
        try:
            context_str = json.dumps(entities, ensure_ascii=False)
            refine_prompt = f"""è¯·å°†ä»¥ä¸‹æœç´¢æŸ¥è¯¢ä¸­çš„é€šç”¨å ä½ç¬¦æ›¿æ¢ä¸ºå…·ä½“çš„å®ä½“åç§°ã€‚

å¯ç”¨å®ä½“ä¿¡æ¯ï¼š
{context_str}

åŸå§‹æŸ¥è¯¢ï¼š{refined_query}

è¯·ç›´æ¥è¾“å‡ºæ›¿æ¢åçš„æœç´¢æŸ¥è¯¢ï¼Œä¸è¦è§£é‡Šï¼š"""

            response = llm.invoke([HumanMessage(content=refine_prompt)])
            llm_refined = response.content.strip()
            if llm_refined and len(llm_refined) < len(refined_query) * 3:  # é˜²æ­¢ LLM è¾“å‡ºè¿‡é•¿
                refined_query = llm_refined
                debug_print(f"[Search Agent] LLM ä¼˜åŒ–å: {refined_query}")
        except Exception as e:
            debug_print(f"[Search Agent] LLM ä¼˜åŒ–å¤±è´¥: {e}")

    return refined_query


SEARCH_PROMPT = """ä½ æ˜¯é«˜å°”å¤«æ—…è¡Œå›¢é˜Ÿçš„**æƒ…æŠ¥å®˜ (Intel Officer)**ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åˆ©ç”¨ Google Search æŸ¥è¯¢æ•°æ®åº“ä¸­æ²¡æœ‰çš„å®æ—¶å…¬å¼€ä¿¡æ¯ã€‚

## æ‰§è¡Œå‡†åˆ™

### 1. ç²¾å‡†å»å™ª
- åªæå–ä¸ä»»åŠ¡ç´§å¯†ç›¸å…³çš„**äº‹å®æ€§ä¿¡æ¯**
- å¿½ç•¥ SEO åºŸè¯ã€å¹¿å‘Šå†…å®¹ã€æ— å…³æ¨å¹¿
- ä¼˜å…ˆå¼•ç”¨æƒå¨æ¥æºï¼ˆå®˜æ–¹ç½‘ç«™ã€çŸ¥ååª’ä½“ã€ä¸“ä¸šè¯„æµ‹ï¼‰

### 2. æ—¶æ•ˆä¼˜å…ˆ
- æ±‡ç‡ã€å¤©æ°”ã€æ–°é—»å¿…é¡»åŸºäº**æœ€æ–°**æœç´¢ç»“æœ
- æ˜ç¡®æ ‡æ³¨ä¿¡æ¯çš„æ—¶æ•ˆæ€§ï¼ˆå¦‚"æˆªè‡³2026å¹´1æœˆ"ï¼‰
- è¿‡æœŸä¿¡æ¯éœ€ç‰¹åˆ«æ³¨æ˜

### 3. æ¥æºå¼•ç”¨
- å…³é”®ä¿¡æ¯éœ€æ³¨æ˜æ¥æº
- æ ¼å¼ï¼šã€Œä¿¡æ¯å†…å®¹ (æ¥æº: xxx)ã€

### 4. æ‹’ç»å¹»è§‰
- æœä¸åˆ°å°±ç›´æ¥è¯´"æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
- **ä¸¥ç¦ç¼–é€ **ä»»ä½•æ•°æ®æˆ–äº‹å®

## è¾“å‡ºæ ¼å¼
è¯·ç”¨ç®€æ´çš„ç»“æ„åŒ–æ ¼å¼å‘ˆç°æœç´¢ç»“æœï¼š

**æœç´¢ä¸»é¢˜**: xxx
**å…³é”®å‘ç°**:
1. xxx (æ¥æº: xxx)
2. xxx (æ¥æº: xxx)
**æ—¶æ•ˆè¯´æ˜**: xxx

---

## å½“å‰æœç´¢ä»»åŠ¡
{search_query}
"""


def _extract_search_query(state: GraphState) -> tuple[str, str]:
    """æå–æœç´¢æŸ¥è¯¢ - ä¼˜å…ˆä½¿ç”¨æ˜ç¡®æŒ‡ä»¤

    ä¼˜å…ˆçº§ï¼š
    1. refined_plan ä¸­çš„ search_agent ä»»åŠ¡æŒ‡ä»¤
    2. supervisor_instructions
    3. ç”¨æˆ·æœ€æ–°æ¶ˆæ¯ (å›é€€)

    Returns:
        (search_query, source) - æœç´¢å†…å®¹å’Œæ¥æºæ ‡è¯†
    """
    # ä¼˜å…ˆçº§ 1: ä» refined_plan ä¸­æå–æœç´¢ä»»åŠ¡
    refined_plan_str = state.get("refined_plan", "")
    if refined_plan_str:
        try:
            plan = json.loads(refined_plan_str)
            task_sequence = plan.get("task_sequence", [])

            # æŸ¥æ‰¾ search_agent ç›¸å…³ä»»åŠ¡
            for task in task_sequence:
                task_lower = task.lower()
                if "search" in task_lower or "æœç´¢" in task:
                    # æå–ä»»åŠ¡æè¿°ä½œä¸ºæœç´¢å†…å®¹
                    # æ ¼å¼: "[search_agent] Search for 'xxx'" æˆ– "æœç´¢ xxx"
                    search_content = task
                    # æ¸…ç†å‰ç¼€
                    for prefix in ["[search_agent]", "[Search]", "search_agent:", "Search:"]:
                        if prefix.lower() in search_content.lower():
                            idx = search_content.lower().find(prefix.lower())
                            search_content = search_content[idx + len(prefix):].strip()
                            break

                    if search_content:
                        return search_content, "refined_plan"
        except (json.JSONDecodeError, AttributeError):
            pass

    # ä¼˜å…ˆçº§ 2: supervisor_instructions
    supervisor_instructions = state.get("supervisor_instructions", "")
    if supervisor_instructions and len(supervisor_instructions) > 5:
        return supervisor_instructions, "supervisor"

    # ä¼˜å…ˆçº§ 3: ç”¨æˆ·æœ€æ–°æ¶ˆæ¯ (å›é€€)
    for msg in reversed(state.get("messages", [])):
        if isinstance(msg, HumanMessage):
            return msg.content, "user_message"

    return "æœªçŸ¥æœç´¢ä»»åŠ¡", "fallback"


def search_agent(state: GraphState, llm: BaseChatModel) -> dict:
    """Search Agent - æƒ…æŠ¥å®˜

    æ‰§è¡Œäº’è”ç½‘æœç´¢ï¼Œå¯¹ç»“æœè¿›è¡Œå»å™ªå’Œç»“æ„åŒ–æ•´ç†ã€‚
    æ”¯æŒåŠ¨æ€ä¸Šä¸‹æ–‡æ›¿æ¢ï¼Œè‡ªåŠ¨å°†å ä½ç¬¦æ›¿æ¢ä¸ºå®é™…å®ä½“åç§°ã€‚

    Args:
        state: å›¾çŠ¶æ€
        llm: LLM å®ä¾‹ï¼ˆå°†ç»‘å®š Google Search å·¥å…·ï¼‰

    Returns:
        åŒ…å« trip_data["search_findings"] å’Œ messages çš„å­—å…¸
    """

    # èŠ‚ç‚¹å…¥å£æ ‡è¯†
    print_node_enter("search_agent")

    # 1. æå–æœç´¢æŸ¥è¯¢ (ä¼˜å…ˆæ˜ç¡®æŒ‡ä»¤)
    raw_query, query_source = _extract_search_query(state)

    print_section("æœç´¢ä»»åŠ¡", "ğŸ”")
    print_kv("æ¥æº", query_source)
    print_kv("åŸå§‹æŸ¥è¯¢", raw_query[:80] + "..." if len(raw_query) > 80 else raw_query)

    # 2. åŠ¨æ€ä¸Šä¸‹æ–‡æ›¿æ¢ï¼ˆè§£å†³å ä½ç¬¦é—®é¢˜ï¼‰
    if _has_placeholder(raw_query):
        debug_print("[Search Agent] æ£€æµ‹åˆ°å ä½ç¬¦ï¼Œæ‰§è¡Œä¸Šä¸‹æ–‡æ›¿æ¢...")
        search_query = _refine_query_with_context(raw_query, state, llm)
        print_kv("ä¼˜åŒ–åæŸ¥è¯¢", search_query[:80] + "..." if len(search_query) > 80 else search_query)
    else:
        search_query = raw_query

    # 3. ç»‘å®š Google Search å·¥å…·
    search_llm = llm.bind_tools([{"google_search": {}}])

    # 4. æ‰§è¡Œæœç´¢
    try:
        messages = [
            SystemMessage(content=SEARCH_PROMPT.format(search_query=search_query)),
            HumanMessage(content=f"è¯·æœç´¢: {search_query}")
        ]
        response = search_llm.invoke(messages)
        search_result = response.content

        debug_print(f"[Search Agent] æœç´¢å®Œæˆï¼Œç»“æœé•¿åº¦: {len(search_result)} å­—ç¬¦")

    except Exception as e:
        debug_print(f"[Search Agent] æœç´¢å¤±è´¥: {e}")
        search_result = f"æœç´¢å¤±è´¥: {str(e)}"

    # 5. è¿”å›ç»“æœ
    query_summary = search_query[:40] + "..." if len(search_query) > 40 else search_query

    # å±•ç¤ºæ•°æ®æ›´æ–°
    print_trip_data_update("search_findings", {"query": query_summary, "result_len": len(search_result)})
    print_routing("search_agent", "supervisor", f"æœç´¢å®Œæˆ: {query_summary}")

    return {
        "trip_data": {
            "search_findings": search_result,
            "search_query": search_query,  # ä¿å­˜åŸå§‹æŸ¥è¯¢ä»¥ä¾¿è¿½æº¯
        },
        "messages": [AIMessage(
            content=f"[Search Agent] å·²å®Œæˆæœç´¢: {query_summary}",
            name="search_agent"
        )]
    }
